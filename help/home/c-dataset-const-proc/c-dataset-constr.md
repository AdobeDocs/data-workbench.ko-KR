---
description: Adobe 데이터 집합에는 데이터 워크벤치 서버에서 로드하여 처리한 데이터가 포함됩니다.
title: 데이터 세트 구성 이해
uuid: 540d159d-3f72-49dd-9929-107f1fc62b2b
exl-id: 111e98b5-d899-4f79-90ce-70f520d527d6
translation-type: tm+mt
source-git-commit: d9df90242ef96188f4e4b5e6d04cfef196b0a628
workflow-type: tm+mt
source-wordcount: '937'
ht-degree: 0%

---

# 데이터 세트 구성 이해{#understanding-dataset-construction}

Adobe 데이터 집합에는 데이터 워크벤치 서버에서 로드하여 처리한 데이터가 포함됩니다.

데이터 워크벤치 서버(InsightServer64.exe)가 데이터를 로드하고 처리하는 데 관련된 단계는 데이터 세트 구성 프로세스를 구성합니다.

>[!NOTE]
>
>Adobe 데이터 집합의 데이터를 처리하고 제공하는 데이터 워크벤치 서버를 데이터 처리 장치 또는 DPU라고 합니다. 처리 서버 또는 쿼리 서버라고도 합니다. 데이터 워크벤치 및 [!DNL Report] 클라이언트는 DPU와 직접 상호 작용합니다.

데이터 세트 구성 중에 데이터 워크벤치 서버는 로그 소스의 소스 데이터를 읽고 특정 데이터 필드에 변형을 적용하고 변형된 필드에서 생성할 확장 차원을 정의합니다. 구성 프로세스는 다음 두 단계로 이루어집니다.*로그 처리* 및 *변환*. 데이터 세트를 구성한 후에는 데이터 세트의 확장 차원을 사용하여 특정 분석 목적으로 파생된 지표와 차원을 만들 수 있습니다.

데이터 세트 구성은 제조 과정과 같습니다. 데이터 세트를 작성하는 데 사용할 데이터(원시 자료)를 선택하고 데이터에 사용할 수 있는 정보를 조작하여 확장된 차원(제작된 제품)을 만드는 데이터 변형(프로세스 단계)을 정의합니다.

<!--
c_log_proc.xml
-->

로그가 필터링되고 변형 단계로 전달할 데이터의 필드가 식별됩니다. 로그 처리 단계가 끝날 때 데이터는 추적 ID(즉, 동일한 추적 ID를 가진 모든 로그 항목이 함께 그룹화됨)로 그룹화되고 시간 단위로 정렬됩니다. 로그 처리 단계 중에는 분석에 사용할 처리된 데이터에 액세스할 수 없습니다.

## 로그 소스 지정 {#section-75279dd6a7304d469735562796741d0f}

로그 소스는 데이터 세트를 작성하는 데 사용할 데이터가 들어 있는 파일입니다. 각 데이터 레코드는 트랜잭션 레코드 또는 이벤트의 단일 인스턴스를 나타내기 때문에 로그 소스에서 사용할 수 있는 데이터를 이벤트 데이터라고 합니다. 또한 각 레코드 또는 로그 항목에는 추적 ID라고 하는 값이 포함되어 있습니다.

>[!NOTE]
>
>로그 소스를 선택할 때 각 로그 항목에 데이터를 그룹화할 최상위 수준을 나타내는 엔티티에 대한 추적 ID가 포함되어 있는지 확인합니다. 예를 들어 웹 사이트 트래픽에서 수집된 데이터로 작업하는 경우 이 엔티티로 방문자를 선택할 수 있습니다. 각 방문자에게는 고유한 추적 ID가 있으며, 특정 사이트 방문자에 대한 모든 데이터를 함께 그룹화할 수 있습니다. 도움이 필요하면 Adobe에 문의하십시오.

로그 소스 이벤트 데이터는 [!DNL Sensors]에 의해 실시간으로 수집되거나 Insight Server에 의해 보관된 데이터 소스에서 추출됩니다. HTTP 및 응용 프로그램 서버에서 센서가 수집한 이벤트 데이터는 Insight 서버로 전송되어 데이터를 압축률이 높은 로그( [!DNL .vsl]) 파일로 변환합니다. 플랫 파일, XML 파일 또는 ODBC 데이터 소스에 있는 이벤트 데이터는 이러한 다른 형식에서 일반적인 로그 필드 세트를 추출하도록 정의하는 디코더를 제공하는 Insight Server에서 읽습니다.

## 변형 정의 {#section-55a8cdb47379484081e53087f074778d}

변형은 이벤트 데이터에서 정보를 추출하거나 조작하도록 정의할 수 있는 일련의 지침입니다. 정의한 각 변환은 각 이벤트 데이터 레코드(로그 항목)에 적용되어 기존 로그 필드를 업데이트하거나 새 필드를 만듭니다. 변환 결과는 로그 항목 조건과 함께 사용하여 로그 처리 중에 데이터세트에서 필터링된 로그 항목을 평가합니다.

데이터 세트 구성 프로세스의 로그 처리 단계에서 일부 유형의 변형을 사용할 수 없습니다.

## 로그 필터링 {#section-6172ca0fb0eb4177925151bb49fdbc02}

데이터 집합에는 변형의 흐름을 벗어나는 데이터를 필터링하는 데 사용되는 여러 매개 변수가 포함되어 있습니다. 필터링은 후속 처리 단계에서 사용할 로그 항목을 지정하는 데 사용됩니다. 예를 들어 필터는 시간 범위, 서버 응답 상태 또는 IP 주소와 사용자 에이전트 정보로 정의할 수 있습니다. [!DNL Log Entry Condition]은 사용자 정의 가능한 필터링 테스트입니다. 테스트는 각 로그 항목의 필드에 있는 특정 조건을 확인하여 해당 항목이 데이터 세트 구성 프로세스에서 계속 진행되어야 하는지 확인합니다. 로그 항목이 조건을 충족하지 않으면 구성 프로세스에서 항목이 제거됩니다.

## 변형 필드 식별 {#section-eef98ca723e54547b887aefdf0514c47}

추가 처리를 위해 로그 처리 단계에서 변형 단계로 데이터 필드를 전달하려면 로그 처리 중에 데이터를 식별해야 합니다. 이 요구 사항은 로그 소스에서 필드를 사용할 수 있는지 아니면 로그 처리 중에 데이터에 적용된 데이터 변환에서 만든 것인지 여부와 관계없이 적용됩니다.

<!--
c_transformation.xml
-->

데이터 세트 생성의 변환 단계에서 로그 처리에서 출력되는 그룹화된 데이터 및 순서가 지정된 데이터에서 처리가 발생합니다. 추가 데이터 변환이 수행되고 분석에 사용할 확장 데이터 차원이 생성됩니다. 변형 단계 중에 변형 단계가 거의 완료에 도달할 때 더 크게 되는 데이터의 통계 샘플에 액세스할 수 있습니다.

## 변형 정의 {#section-001b3fd4c1dd4dd38a5536872bc9de68}

데이터 세트 구성 프로세스의 변형 단계에서 사용할 변형을 정의하여 확장 차원을 쉽게 생성할 수 있습니다. 각 변환은 로그 처리에서 전달된 각 이벤트 데이터 레코드(로그 항목)에 적용됩니다.

## 로그 필터링 {#section-3fed0a00ca344a719b5e8db363f64f06}

변환 중에 [!DNL Log Entry Condition]을 적용하여 로그 처리에서 나오는 각 로그 항목의 필드에 특정 조건을 찾을 수 있습니다. 로그 항목이 조건을 충족하지 않으면 구성 프로세스에서 항목이 제거됩니다.

## 확장 차원 정의 {#section-25efafd0bfc84c86b9717d453a88c91b}

확장된 차원은 데이터 세트 구성 프로세스의 최종 결과입니다. 데이터의 로그 필드 간 관계를 나타냅니다. 시각화를 만들거나, 확장 지표를 만들거나, 분석을 수행하여 비즈니스와 관련된 작업과 문제를 이해할 수 있습니다.
