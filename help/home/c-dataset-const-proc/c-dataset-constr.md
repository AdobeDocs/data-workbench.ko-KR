---
description: Adobe 데이터 세트에는 Data Workbench 서버에서 로드 및 처리한 데이터가 포함되어 있습니다.
title: 데이터 세트 구성 이해
uuid: 540d159d-3f72-49dd-9929-107f1fc62b2b
exl-id: 111e98b5-d899-4f79-90ce-70f520d527d6
source-git-commit: d9df90242ef96188f4e4b5e6d04cfef196b0a628
workflow-type: tm+mt
source-wordcount: '937'
ht-degree: 0%

---

# 데이터 세트 구성 이해{#understanding-dataset-construction}

Adobe 데이터 세트에는 Data Workbench 서버에서 로드 및 처리한 데이터가 포함되어 있습니다.

Data Workbench 서버(InsightServer64.exe)의 데이터 로드 및 처리와 관련된 단계는 데이터 세트 구성 프로세스를 구성합니다.

>[!NOTE]
>
>Adobe 데이터 집합에서 데이터를 처리하고 제공하는 Data Workbench 서버를 데이터 처리 단위 또는 DPU라고 합니다. 처리 서버 또는 쿼리 서버라고도 합니다. Data Workbench 및 [!DNL Report] 클라이언트는 DPU와 직접 상호 작용합니다.

데이터 집합을 구성하는 동안 Data Workbench 서버는 로그 소스에서 소스 데이터를 읽고, 데이터의 특정 필드에 변환을 적용하고, 변형된 필드에서 생성할 확장 차원을 정의합니다. 구성 프로세스는 다음 두 단계로 수행됩니다.*로그 처리* 및 *변환*. 데이터 세트가 만들어지면 데이터 세트의 확장 차원을 사용하여 특정 분석 목적으로 파생된 지표 및 차원을 만들 수 있습니다.

데이터 집합 구성은 제조 과정과 같습니다. 데이터 집합을 만드는 데 사용할 데이터(원시 재료)를 선택하고 데이터에서 사용할 수 있는 정보를 조작하는 데이터 변환(프로세스 단계)을 정의하여 확장된 차원(제조 제품)을 만듭니다.

<!--
c_log_proc.xml
-->

로그가 필터링되고 변환 단계에 전달될 데이터의 필드가 식별됩니다. 로그 처리 단계가 끝날 때 데이터는 추적 ID(즉, 추적 ID가 동일한 모든 로그 항목이 함께 그룹화됨)별로 그룹화되고 제시간에 정렬됩니다. 로그 처리 단계 중에는 분석에 사용할 처리된 데이터에 액세스할 수 없습니다.

## 로그 소스 지정 {#section-75279dd6a7304d469735562796741d0f}

로그 소스는 데이터 집합을 만드는 데 사용할 데이터가 포함된 파일입니다. 각 데이터 레코드는 트랜잭션 레코드 또는 이벤트의 단일 인스턴스를 나타내므로 로그 소스에서 사용할 수 있는 데이터를 이벤트 데이터라고 합니다. 또한 각 레코드 또는 로그 항목에는 추적 ID라고 하는 값이 포함되어 있습니다.

>[!NOTE]
>
>로그 소스를 선택할 때는 각 로그 항목에 데이터를 그룹화할 최상위 수준을 나타내는 엔티티에 대한 추적 ID가 포함되어 있는지 확인하십시오. 예를 들어, 웹 사이트 트래픽에서 수집된 데이터로 작업하는 경우, 방문자를 이 엔티티로 선택할 수 있습니다. 각 방문자에게는 고유한 추적 ID가 있으며, 특정 사이트 방문자에 대한 모든 데이터를 함께 그룹화할 수 있습니다. 도움이 필요하면 Adobe에게 문의하십시오.

로그 소스 이벤트 데이터는 [!DNL Sensors]에 의해 실시간으로 수집되거나 Insight Server에 의해 보관된 데이터 소스에서 추출됩니다. HTTP 및 애플리케이션 서버에서 센서가 수집한 이벤트 데이터는 Insight Server로 전송되며 이 데이터는 압축된 로그( [!DNL .vsl]) 파일로 변환됩니다. 플랫 파일, XML 파일 또는 ODBC 데이터 소스에 있는 이벤트 데이터는 이러한 다른 형식에서 일반적인 로그 필드 세트를 추출하도록 정의하는 디코더를 제공하는 Insight Server에서 읽습니다.

## 변형 정의 {#section-55a8cdb47379484081e53087f074778d}

변환은 이벤트 데이터의 정보를 추출하거나 조작하도록 정의할 수 있는 일련의 지침입니다. 정의한 각 변환은 각 이벤트 데이터 레코드(로그 항목)에 적용되어 기존 로그 필드를 업데이트하거나 새 필드를 생성합니다. 변환 결과는 로그 항목 조건과 함께 사용하여 로그 처리 중에 데이터 집합에서 필터링되는 로그 항목을 평가합니다.

데이터 집합 구성 프로세스의 로그 처리 단계에서 일부 변형 유형을 사용할 수는 없습니다.

## 필터링 로그 {#section-6172ca0fb0eb4177925151bb49fdbc02}

데이터 세트에는 변형에서 나온 데이터를 필터링하는 데 사용되는 여러 매개 변수가 포함되어 있습니다. 필터링은 후속 처리 단계에서 사용할 로그 항목을 지정하는 데 사용됩니다. 예를 들어 필터는 시간 범위, 서버 응답 상태 또는 IP 주소 및 사용자 에이전트 정보로 정의할 수 있습니다. [!DNL Log Entry Condition]은 사용자 정의 가능한 필터링 테스트입니다. 테스트는 각 로그 항목의 필드에서 특정 조건을 검색하여 데이터 집합 구성 프로세스에서 해당 항목이 더 진행되어야 하는지 여부를 결정합니다. 로그 항목이 조건을 충족하지 않으면 구성 프로세스에서 항목이 제거됩니다.

## 변형 필드 식별 {#section-eef98ca723e54547b887aefdf0514c47}

추가 처리를 위해 데이터 필드를 로그 처리 단계에서 변형 단계로 전달해야 하는 경우 로그 처리 중에 식별해야 합니다. 이 요구 사항은 로그 소스에서 필드를 사용할 수 있는지 아니면 로그 처리 중에 데이터에 적용된 데이터 변환에서 작성하는지에 관계없이 적용됩니다.

<!--
c_transformation.xml
-->

데이터 집합을 구성하는 변환 단계 동안 로그 처리에서 출력되는 그룹화된 순차 데이터에서 처리가 수행됩니다. 추가 데이터 변환이 수행되고 분석에 사용할 확장 데이터 차원이 만들어집니다. 변환 단계 동안 변환 단계가 거의 완료됨에 따라 더 크게 되는 데이터의 통계 샘플에 액세스할 수 있습니다.

## 변형 정의 {#section-001b3fd4c1dd4dd38a5536872bc9de68}

데이터 집합 구성 프로세스의 변형 단계 동안 사용할 변형을 정의하여 확장 차원을 쉽게 만들 수 있습니다. 각 변환은 로그 처리에서 전달된 각 이벤트 데이터 레코드(로그 항목)에 적용됩니다.

## 필터링 로그 {#section-3fed0a00ca344a719b5e8db363f64f06}

변환 중에 [!DNL Log Entry Condition]을 적용하여 로그 처리에서 나오는 각 로그 항목의 필드에서 특정 조건을 찾을 수 있습니다. 로그 항목이 조건을 충족하지 않으면 구성 프로세스에서 항목이 제거됩니다.

## 확장 차원 정의 {#section-25efafd0bfc84c86b9717d453a88c91b}

확장 차원은 데이터 집합 구성 프로세스의 최종 제품입니다. 이는 데이터의 로그 필드 간 관계를 나타냅니다. 이 도구를 사용하여 시각화를 만들거나, 확장 지표를 작성하거나, 분석을 수행하여 비즈니스 관련 작업 및 문제를 파악합니다.
